This was a great project as we got a 15/15 for improving code and including new ML models. We kept the data fair to the original models and used the same format for the new models. We included Logistic Regression, Neural Networks, and AdaBoost. Our findings were NN did the best on data without outlier removal and on the robust scalar SVM did the best. 

In conclusion, the NN has proven to be the best-performing model, with accuracy and F1 of 92% and 92% respectively, when trained on the dataset without outliers. The project successfully developed a binary classification model for apple quality that outperformed the accuracy set by Nukman Hakimâ€™s SVM model on the dataset without outliers; with the Robust scaled dataset the performance of the NN and SVM is very close (88.6% Vs 91.5%). The comparison of different outlier-handling methods provided valuable insights into model performance, indicating the importance of robust preprocessing techniques in improving model generalization and performance metrics. Further analysis, including feature importance, scaling techniques, model interpretation, and hyperparameter tuning, could provide additional insights and improvements for continued enhancement of the model's predictive capabilities.


![image](https://github.com/Kerims23/MLAppleProject/assets/55418044/16185e92-446a-45f4-a606-cacd7b273e7e)
